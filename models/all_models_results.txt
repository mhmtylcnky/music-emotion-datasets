
--- Random Forest ---
Accuracy: 0.7798
              precision    recall  f1-score   support

       happy       0.91      0.62      0.74       109
         sad       0.71      0.94      0.81       109

    accuracy                           0.78       218
   macro avg       0.81      0.78      0.77       218
weighted avg       0.81      0.78      0.77       218

============================================================

--- Logistic Regression ---
Accuracy: 0.7294
              precision    recall  f1-score   support

       happy       0.84      0.57      0.68       109
         sad       0.67      0.89      0.77       109

    accuracy                           0.73       218
   macro avg       0.76      0.73      0.72       218
weighted avg       0.76      0.73      0.72       218

============================================================

--- Naive Bayes ---
Accuracy: 0.6239
              precision    recall  f1-score   support

       happy       0.59      0.79      0.68       109
         sad       0.68      0.46      0.55       109

    accuracy                           0.62       218
   macro avg       0.64      0.62      0.61       218
weighted avg       0.64      0.62      0.61       218

============================================================

--- Svm ---
Accuracy: 0.6422
              precision    recall  f1-score   support

       happy       0.67      0.56      0.61       109
         sad       0.62      0.72      0.67       109

    accuracy                           0.64       218
   macro avg       0.65      0.64      0.64       218
weighted avg       0.65      0.64      0.64       218

============================================================

--- Adaboost ---
Accuracy: 0.7385
              precision    recall  f1-score   support

       happy       0.85      0.58      0.69       109
         sad       0.68      0.90      0.77       109

    accuracy                           0.74       218
   macro avg       0.77      0.74      0.73       218
weighted avg       0.77      0.74      0.73       218

============================================================

--- Ann ---
Accuracy: 0.5826
              precision    recall  f1-score   support

       happy       0.95      0.17      0.29       109
         sad       0.55      0.99      0.70       109

    accuracy                           0.58       218
   macro avg       0.75      0.58      0.50       218
weighted avg       0.75      0.58      0.50       218

============================================================

--- Decision Tree ---
Accuracy: 0.6422
              precision    recall  f1-score   support

       happy       0.65      0.61      0.63       109
         sad       0.63      0.68      0.65       109

    accuracy                           0.64       218
   macro avg       0.64      0.64      0.64       218
weighted avg       0.64      0.64      0.64       218

============================================================

--- Knn ---
Accuracy: 0.5780
              precision    recall  f1-score   support

       happy       0.60      0.45      0.52       109
         sad       0.56      0.71      0.63       109

    accuracy                           0.58       218
   macro avg       0.58      0.58      0.57       218
weighted avg       0.58      0.58      0.57       218

============================================================

--- Xgboost ---
Accuracy: 0.7615
              precision    recall  f1-score   support

       happy       0.91      0.58      0.71       109
         sad       0.69      0.94      0.80       109

    accuracy                           0.76       218
   macro avg       0.80      0.76      0.75       218
weighted avg       0.80      0.76      0.75       218

============================================================
